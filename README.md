# Time Cross Adaptive Self Attention( TCSA ) based Imputation model

 Time-Cross Adaptive Self-Attention (TCSA) model  for multivariate Time Series Imputation Model for Sparse  and Irregular Data

 ## model Architecture 
 
![Model archi Diagram drawio](https://github.com/user-attachments/assets/00851210-1a15-403d-92bd-2d68bd184f28)



# â³ Time-Cross Adaptive Self-Attention (TCSA) for Multivariate Time Series Imputation

This repository presents a novel deep learning architectureâ€”**Time-Cross Adaptive Self-Attention (TCSA)**â€”designed for imputing missing values in sparse and irregular multivariate time series data. The model leverages temporal and cross-variable dependencies using adaptive attention mechanisms, making it ideal for real-world datasets with non-uniform sampling and high missingness.

## ğŸ“Œ Project Overview

Multivariate time series data often suffer from missing values due to sensor failures, irregular sampling, or transmission errors. Traditional imputation methods fail to capture temporal dynamics and inter-variable relationships. TCSA addresses this by:

- Modeling both **temporal** and **cross-variable** dependencies
- Using **adaptive self-attention** to weigh relevant time steps and features
- Handling **sparse and irregular** data without interpolation

## ğŸ§  Model Architecture

The TCSA model consists of the following components:

### ğŸ”¹ Temporal Encoder
- Captures intra-variable temporal patterns
- Uses self-attention over time steps
- Learns dynamic temporal weights

### ğŸ”¹ Cross-Variable Encoder
- Captures inter-variable correlations
- Applies attention across feature dimensions
- Enables adaptive feature fusion

### ğŸ”¹ Fusion Layer
- Combines temporal and cross-variable embeddings
- Applies residual connections and layer normalization

### ğŸ”¹ Imputation Head
- Predicts missing values using fused representations
- Optimized with masked loss functions to focus on missing entries

## ğŸš€ Technologies Used

- **PyTorch**: Core deep learning framework
- **NumPy & Pandas**: Data manipulation and preprocessing
- **Matplotlib**: Visualization of imputation performance
- **Jupyter Notebook**: Interactive experimentation
- **Python Scripts**: Modular training and evaluation

## ğŸ“ Repository Structure

```text
â”œâ”€â”€ DataSet_file/                   # Raw and processed time series data
â”œâ”€â”€ Modeling/                       # TCSA model implementation
â”œâ”€â”€ dataset_creation_script/       # Scripts for generating synthetic or real datasets
â”œâ”€â”€ config.py                       # Hyperparameter configuration
â”œâ”€â”€ plot.py                         # Visualization utilities
â”œâ”€â”€ random.ipynb                    # Exploratory analysis and testing
â”œâ”€â”€ test.ipynb                      # Evaluation notebook
â”œâ”€â”€ requirement.txt                 # Python dependencies
â”œâ”€â”€ LICENSE                         # GPL-3.0 license
â”œâ”€â”€ README.md                       # Project documentation
```
## ğŸ› ï¸ How to Install

To get started, clone the repository and set up your environment:

```bash
git clone https://github.com/arvind207kumar/Time-Cross-Adaptive-Self-Attention-TCSA-based-Imputation-model-.git
cd Time-Cross-Adaptive-Self-Attention-TCSA-based-Imputation-model-
```
Install all required Python packages using the provided `requirement.txt` file:

```bash
## ğŸ“¦ Install Dependencies
pip install -r requirement.txt
```

## ğŸ“ Prepare the Dataset

To prepare your dataset:

- Use scripts in the `dataset_creation_script/` folder to generate or format time series data.
- Place the processed dataset files into the `DataSet_file/` directory.
- You can use synthetic data or real-world datasets depending on your use case.

---

## ğŸš€ Train and Evaluate the Model

To train and evaluate the TCSA model:

- Open and run `random.ipynb` for exploratory training and visualization.
- Use `test.ipynb` for structured evaluation and performance metrics.
- Modify `config.py` to adjust hyperparameters like:

  - Learning rate  
  - Batch size  
  - Number of epochs

---

## ğŸ“Š Results

The TCSA model demonstrates strong performance across multiple benchmarks:

- âœ… **Imputation Accuracy**: High fidelity reconstruction of missing values across multiple datasets
- ğŸ” **Robustness**: Handles varying levels of sparsity and irregularity
- ğŸ“ˆ **Visualization**: Clear plots showing original vs imputed sequences
- ğŸ§ª **Generalization**: Performs well across synthetic and real-world time series

---

## ğŸ”® Future Work

Planned enhancements and extensions include:

- ğŸ“¦ **Model Export**: Convert to TorchScript or ONNX for deployment
- ğŸ§  **Multivariate Forecasting**: Extend TCSA for predictive modeling
- ğŸ§ª **Benchmarking**: Compare against state-of-the-art imputation baselines
- ğŸŒ **Domain Adaptation**: Apply to healthcare, finance, and IoT datasets
- ğŸ“± **Interactive Dashboard**: Build a Streamlit app for visual imputation

