{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypots.imputation import SAITS as dualbranch_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import benchpots\n",
    "from pypots.utils.random import set_random_seed\n",
    "\n",
    "##  calc_mre , calc_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from benchpots.datasets import preprocess_italy_air_quality  # Import the preprocess_italy_air_quality function directly\n",
    "\n",
    "# Provide the 'n_steps' argument\n",
    "# Call the function to get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 14:34:32 [INFO]: Have set the random seed as 2022 for numpy and pytorch.\n",
      "2024-11-08 14:34:32 [INFO]: You're using dataset physionet_2012, please cite it properly in your work. You can find its reference information at the below link: \n",
      "https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/physionet_2012\n",
      "2024-11-08 14:34:32 [INFO]: Dataset physionet_2012 has already been downloaded. Processing directly...\n",
      "2024-11-08 14:34:32 [INFO]: Dataset physionet_2012 has already been cached. Loading from cache directly...\n",
      "2024-11-08 14:34:32 [INFO]: Loaded successfully!\n",
      "2024-11-08 14:35:06 [WARNING]: Note that physionet_2012 has sparse observations in the time series, hence we don't add additional missing values to the training dataset. \n",
      "2024-11-08 14:35:06 [INFO]: 68826 values masked out in the val set as ground truth, take 9.98% of the original observed values\n",
      "2024-11-08 14:35:06 [INFO]: 86353 values masked out in the test set as ground truth, take 9.99% of the original observed values\n",
      "2024-11-08 14:35:06 [INFO]: Total sample number: 11988\n",
      "2024-11-08 14:35:06 [INFO]: Training set size: 7671 (63.99%)\n",
      "2024-11-08 14:35:06 [INFO]: Validation set size: 1918 (16.00%)\n",
      "2024-11-08 14:35:06 [INFO]: Test set size: 2399 (20.01%)\n",
      "2024-11-08 14:35:06 [INFO]: Number of steps: 48\n",
      "2024-11-08 14:35:06 [INFO]: Number of features: 37\n",
      "2024-11-08 14:35:06 [INFO]: Train set missing rate: 79.69%\n",
      "2024-11-08 14:35:06 [INFO]: Validating set missing rate: 81.78%\n",
      "2024-11-08 14:35:06 [INFO]: Test set missing rate: 81.75%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['n_classes', 'n_steps', 'n_features', 'scaler', 'train_X', 'train_y', 'train_ICUType', 'val_X', 'val_y', 'val_ICUType', 'test_X', 'test_y', 'test_ICUType', 'val_X_ori', 'test_X_ori'])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import benchpots\n",
    "from pypots.utils.random import set_random_seed\n",
    "\n",
    "set_random_seed()\n",
    "\n",
    "# Load the PhysioNet-2012 dataset\n",
    "physionet2012_dataset = benchpots.datasets.preprocess_physionet2012(subset=\"all\", rate=0.1)\n",
    "\n",
    "# Take a look at the generated PhysioNet-2012 dataset, you'll find that everything has been prepared for you,\n",
    "# data splitting, normalization, additional artificially-missing values for evaluation, etc.\n",
    "print(physionet2012_dataset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_for_training = {\n",
    "    \"X\": physionet2012_dataset['train_X'],\n",
    "}\n",
    "# assemble the datasets for validation\n",
    "dataset_for_validating = {\n",
    "    \"X\": physionet2012_dataset['val_X'],\n",
    "    \"X_ori\": physionet2012_dataset['val_X_ori'],\n",
    "}\n",
    "# assemble the datasets for test\n",
    "dataset_for_testing = {\n",
    "    \"X\": physionet2012_dataset['test_X'],\n",
    "}\n",
    "## calculate the mask to indicate the ground truth positions in test_X_ori, will be used by metric funcs to evaluate models\n",
    "test_X_indicating_mask = np.isnan(physionet2012_dataset['test_X_ori']) ^ np.isnan(physionet2012_dataset['test_X'])\n",
    "test_X_ori = np.nan_to_num(physionet2012_dataset['test_X_ori'])  # metric functions do not accpet input with NaNs, hence fill NaNs with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 14:37:03 [INFO]: No given device, using default device: cuda\n",
      "2024-11-08 14:37:03 [INFO]: Model files will be saved to D:\\proj\\Time series imputation\\weight_filel\\model\\20241108_T143703\n",
      "2024-11-08 14:37:03 [INFO]: Tensorboard file will be saved to D:\\proj\\Time series imputation\\weight_filel\\model\\20241108_T143703\\tensorboard\n",
      "2024-11-08 14:37:03 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 720,182\n",
      "2024-11-08 14:37:09 [INFO]: Epoch 001 - training loss: 0.7248, validation loss: 6.2435\n",
      "2024-11-08 14:37:09 [INFO]: Saved the model to D:\\proj\\Time series imputation\\weight_filel\\model\\20241108_T143703\\SAITS_epoch1_loss6.2435014051695665.pypots\n",
      "2024-11-08 14:37:15 [INFO]: Epoch 002 - training loss: 0.5364, validation loss: 6.2122\n",
      "2024-11-08 14:37:15 [INFO]: Saved the model to D:\\proj\\Time series imputation\\weight_filel\\model\\20241108_T143703\\SAITS_epoch2_loss6.212190834432841.pypots\n",
      "2024-11-08 14:37:21 [INFO]: Epoch 003 - training loss: 0.4928, validation loss: 6.1680\n",
      "2024-11-08 14:37:21 [INFO]: Saved the model to D:\\proj\\Time series imputation\\weight_filel\\model\\20241108_T143703\\SAITS_epoch3_loss6.167979047199091.pypots\n",
      "2024-11-08 14:37:26 [INFO]: Epoch 004 - training loss: 0.4591, validation loss: 6.1524\n",
      "2024-11-08 14:37:26 [INFO]: Saved the model to D:\\proj\\Time series imputation\\weight_filel\\model\\20241108_T143703\\SAITS_epoch4_loss6.152446892857552.pypots\n",
      "2024-11-08 14:37:32 [INFO]: Epoch 005 - training loss: 0.4396, validation loss: 6.1470\n",
      "2024-11-08 14:37:32 [INFO]: Saved the model to D:\\proj\\Time series imputation\\weight_filel\\model\\20241108_T143703\\SAITS_epoch5_loss6.146997062365214.pypots\n",
      "2024-11-08 14:37:38 [INFO]: Epoch 006 - training loss: 0.4217, validation loss: 6.1369\n",
      "2024-11-08 14:37:38 [INFO]: Saved the model to D:\\proj\\Time series imputation\\weight_filel\\model\\20241108_T143703\\SAITS_epoch6_loss6.1369178399443625.pypots\n",
      "2024-11-08 14:37:44 [INFO]: Epoch 007 - training loss: 0.4078, validation loss: 6.1354\n",
      "2024-11-08 14:37:44 [INFO]: Saved the model to D:\\proj\\Time series imputation\\weight_filel\\model\\20241108_T143703\\SAITS_epoch7_loss6.135373975833257.pypots\n",
      "2024-11-08 14:37:50 [INFO]: Epoch 008 - training loss: 0.3976, validation loss: 6.1269\n",
      "2024-11-08 14:37:50 [INFO]: Saved the model to D:\\proj\\Time series imputation\\weight_filel\\model\\20241108_T143703\\SAITS_epoch8_loss6.126933321605126.pypots\n",
      "2024-11-08 14:37:56 [INFO]: Epoch 009 - training loss: 0.3877, validation loss: 6.1271\n",
      "2024-11-08 14:38:01 [INFO]: Epoch 010 - training loss: 0.3808, validation loss: 6.1253\n",
      "2024-11-08 14:38:02 [INFO]: Saved the model to D:\\proj\\Time series imputation\\weight_filel\\model\\20241108_T143703\\SAITS_epoch10_loss6.125270951042572.pypots\n",
      "2024-11-08 14:38:02 [INFO]: Finished training. The best model is from epoch#10.\n",
      "2024-11-08 14:38:02 [INFO]: Saved the model to D:\\proj\\Time series imputation\\weight_filel\\model\\20241108_T143703\\SAITS.pypots\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing mean absolute error: 0.2427\n"
     ]
    }
   ],
   "source": [
    "from pypots.utils.metrics import calc_mae\n",
    "from pypots.optim import Adam\n",
    "\n",
    "\n",
    "# initialize the model\n",
    "model = dualbranch_model(\n",
    "    n_steps=physionet2012_dataset['n_steps'],\n",
    "    n_features=physionet2012_dataset['n_features'],\n",
    "    n_layers=1,\n",
    "    d_model=256,\n",
    "    d_ffn=128,\n",
    "    n_heads=4,\n",
    "    d_k=64,\n",
    "    d_v=64,\n",
    "    dropout=0.1,\n",
    "    ORT_weight=1, \n",
    "    MIT_weight=1,\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    patience=3,\n",
    "    optimizer=Adam(lr=1e-3),\n",
    "    num_workers=0,\n",
    "    device=None,\n",
    "    saving_path=\"D:\\proj\\Time series imputation\\weight_filel\\model\",\n",
    "    model_saving_strategy=\"best\",\n",
    ")\n",
    "\n",
    "# train the model on the training set, and validate it on the validating set to select the best model for testing in the next step\n",
    "model.fit(train_set=dataset_for_training, val_set=dataset_for_validating)\n",
    "\n",
    "# the testing stage, impute the originally-missing values and artificially-missing values in the test set\n",
    "model_results = model.predict(dataset_for_testing)\n",
    "model_imputation = model_results[\"imputation\"]\n",
    "\n",
    "# calculate mean absolute error on the ground truth (artificially-missing values)\n",
    "testing_mae = calc_mae(\n",
    "    model_imputation,\n",
    "    test_X_ori,\n",
    "    test_X_indicating_mask,\n",
    ")\n",
    "print(f\"Testing mean absolute error: {testing_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing mre : 0.3531\n"
     ]
    }
   ],
   "source": [
    "testing_mre = calc_mre( # call the function correctly\n",
    "    model_imputation,\n",
    "    test_X_ori,\n",
    "    test_X_indicating_mask,\n",
    ")\n",
    "print(f\"Testing mre : {testing_mre:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[False False False ... False False False]\n",
      "  [False False False ...  True False False]\n",
      "  [False False False ... False False False]\n",
      "  ...\n",
      "  [False False False ... False False False]\n",
      "  [False False False ... False False False]\n",
      "  [False False False ... False False False]]\n",
      "\n",
      " [[False False False ... False False False]\n",
      "  [False False False ... False False False]\n",
      "  [False False False ... False False False]\n",
      "  ...\n",
      "  [False False False ... False False False]\n",
      "  [False False False ... False False False]\n",
      "  [False False False ... False False False]]\n",
      "\n",
      " [[False False False ... False False False]\n",
      "  [False False False ... False False False]\n",
      "  [False False False ... False False False]\n",
      "  ...\n",
      "  [False False False ... False False False]\n",
      "  [False False False ... False False False]\n",
      "  [False False False ... False False False]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[False False False ... False False False]\n",
      "  [False False False ... False False False]\n",
      "  [False False False ... False False False]\n",
      "  ...\n",
      "  [False False False ... False False False]\n",
      "  [False False False ... False False False]\n",
      "  [False False False ... False False False]]\n",
      "\n",
      " [[False False False ... False False False]\n",
      "  [False False False ... False False False]\n",
      "  [False False False ... False False False]\n",
      "  ...\n",
      "  [False False False ... False False False]\n",
      "  [False False False ... False False False]\n",
      "  [False False False ... False False False]]\n",
      "\n",
      " [[False False False ... False False False]\n",
      "  [False  True False ... False False False]\n",
      "  [False False False ... False False False]\n",
      "  ...\n",
      "  [False False False ... False False False]\n",
      "  [False False False ... False False False]\n",
      "  [False False False ... False False False]]]\n"
     ]
    }
   ],
   "source": [
    "print(test_X_indicating_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-4.29392219e-01 -3.57200325e-01 -2.79296875e-01 ... -3.46589461e-02\n",
      "   -1.05640221e+00  3.79583798e-03]\n",
      "  [ 3.89896221e-02 -2.52709717e-01 -1.74883366e-01 ... -1.20010614e-01\n",
      "   -1.05640221e+00  1.27250291e-02]\n",
      "  [-4.46544826e-01 -3.46824586e-01 -2.55950212e-01 ... -2.83666067e-02\n",
      "   -1.05640221e+00 -7.30885006e-03]\n",
      "  ...\n",
      "  [-4.37366366e-01 -3.72983336e-01 -3.68832082e-01 ... -2.64587905e-03\n",
      "   -1.05640221e+00  3.52167524e-02]\n",
      "  [-3.22087526e-01 -3.78736973e-01 -3.43933761e-01 ... -2.31846236e-02\n",
      "   -1.05640221e+00  1.12316404e-02]\n",
      "  [-4.20116931e-01 -3.44024479e-01 -3.59765947e-01 ... -7.70069333e-03\n",
      "   -1.05640221e+00  2.32745782e-02]]\n",
      "\n",
      " [[-3.26734334e-01 -4.21668768e-01 -3.39395195e-01 ... -5.27377650e-02\n",
      "   -3.35708523e+00  3.87648772e-03]\n",
      "  [-4.14426029e-01 -4.55937624e-01 -4.01236892e-01 ... -8.86489451e-02\n",
      "   -5.08544385e-01 -1.77896582e-02]\n",
      "  [-3.88349056e-01 -4.69787538e-01 -3.59554559e-01 ... -1.61971122e-01\n",
      "   -5.00287414e-01 -1.79139785e-02]\n",
      "  ...\n",
      "  [-3.87043983e-01 -4.11905944e-01 -3.69032711e-01 ... -6.19113371e-02\n",
      "   -2.37994313e-01  2.34698877e-03]\n",
      "  [-3.67381006e-01 -3.95988673e-01 -3.67565513e-01 ... -5.94719052e-02\n",
      "   -2.43167654e-01  2.18970980e-03]\n",
      "  [-3.53317678e-01 -3.83687556e-01 -3.58576775e-01 ... -6.43616468e-02\n",
      "   -2.37526476e-01 -1.15760742e-03]]\n",
      "\n",
      " [[-2.47852862e-01 -4.18565631e-01 -3.43773514e-01 ...  9.80054960e-04\n",
      "   -9.64693844e-01 -1.75794344e-02]\n",
      "  [-1.81911230e-01 -4.13749009e-01 -3.08656722e-01 ...  2.41243746e-03\n",
      "   -3.90338123e-01 -1.44244079e-02]\n",
      "  [-1.45450518e-01 -4.42665666e-01 -3.06693465e-01 ...  8.51141661e-03\n",
      "   -3.30438554e-01 -2.01566238e-02]\n",
      "  ...\n",
      "  [-3.38970959e-01 -3.85197580e-01 -3.33322734e-01 ... -2.37399247e-02\n",
      "   -1.70531839e-01  9.09281988e-03]\n",
      "  [-3.81056994e-01 -4.03916985e-01 -3.81195575e-01 ... -2.21187826e-02\n",
      "   -1.79314792e-01  9.25761182e-04]\n",
      "  [-3.74385715e-01 -3.73188585e-01 -3.78740132e-01 ... -1.88292135e-02\n",
      "   -1.78221494e-01  5.92891127e-04]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-2.55650878e-01 -3.71683389e-01 -3.31286877e-01 ... -4.21391055e-02\n",
      "   -1.01652896e+00 -2.23886594e-02]\n",
      "  [-2.09467083e-01 -3.71217817e-01 -3.43666255e-01 ... -3.82520184e-02\n",
      "   -1.01652896e+00 -1.64937600e-02]\n",
      "  [-2.60957628e-01 -3.72724175e-01 -3.21686238e-01 ... -4.36678678e-02\n",
      "   -1.01652896e+00 -2.11231504e-02]\n",
      "  ...\n",
      "  [-1.84625685e-01 -3.35663170e-01 -3.09857070e-01 ... -1.72696605e-01\n",
      "   -1.01652896e+00  4.18930054e-02]\n",
      "  [-4.02903944e-01 -3.70678186e-01 -3.26169372e-01 ... -3.83089557e-02\n",
      "   -1.11858916e+00  3.00966320e-03]\n",
      "  [-4.11336899e-01 -3.76858503e-01 -3.18419904e-01 ... -7.33207986e-02\n",
      "   -1.10721600e+00  1.94298662e-03]]\n",
      "\n",
      " [[-3.37553233e-01 -3.91870230e-01 -3.41187656e-01 ...  3.88264060e-02\n",
      "    5.20724505e-02  5.64960204e-03]\n",
      "  [-3.69834185e-01 -4.07850683e-01 -3.54016066e-01 ...  2.92457361e-02\n",
      "    5.20724505e-02  1.12821311e-02]\n",
      "  [ 3.34487744e-02 -3.10450613e-01 -2.94449896e-01 ...  2.36080512e-01\n",
      "    5.20724505e-02  6.23001233e-02]\n",
      "  ...\n",
      "  [-4.00813073e-01 -3.94036591e-01 -3.54610741e-01 ...  3.01764794e-02\n",
      "    5.20724505e-02  3.43832299e-02]\n",
      "  [-4.26597387e-01 -3.73302519e-01 -3.65796447e-01 ...  5.33817373e-02\n",
      "    5.20724505e-02  3.25249843e-02]\n",
      "  [-3.68426144e-01 -3.34539175e-01 -3.40279490e-01 ...  6.35475889e-02\n",
      "   -2.06487253e-02  2.89463922e-02]]\n",
      "\n",
      " [[-3.43266159e-01 -4.01860714e-01 -2.02291831e-01 ...  8.21216106e-02\n",
      "   -4.02481884e-01 -1.15677170e-01]\n",
      "  [-3.10083777e-01 -3.77108872e-01 -2.88216561e-01 ...  1.49003729e-01\n",
      "   -2.57869422e-01 -8.66300836e-02]\n",
      "  [-3.20657432e-01 -3.91941637e-01 -2.77943879e-01 ...  4.00875360e-02\n",
      "   -2.13159874e-01 -4.49762903e-02]\n",
      "  ...\n",
      "  [-3.92122686e-01 -4.11853015e-01 -3.27871025e-01 ... -2.99360920e-02\n",
      "   -1.82479694e-01 -1.34424483e-02]\n",
      "  [-3.84604752e-01 -4.16208148e-01 -3.56767625e-01 ... -8.09062831e-03\n",
      "   -1.90538064e-01 -4.10939241e-03]\n",
      "  [-3.86435360e-01 -4.01812732e-01 -3.37283075e-01 ... -1.50105311e-02\n",
      "   -1.59227133e-01 -3.54262325e-03]]]\n"
     ]
    }
   ],
   "source": [
    "print(model_imputation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'beijing_multisite_air_quality', 'electricity_load_diagrams', 'electricity_transformer_temperature', 'italy_air_quality', 'pems_traffic', 'physionet_2012', 'physionet_2019', 'preprocess_beijing_air_quality', 'preprocess_electricity_load_diagrams', 'preprocess_ett', 'preprocess_italy_air_quality', 'preprocess_pems_traffic', 'preprocess_physionet2012', 'preprocess_physionet2019', 'preprocess_random_walk', 'preprocess_solar_alabama', 'preprocess_ucr_uea_datasets', 'random_walk', 'solar_alabama', 'ucr_uea_datasets']\n"
     ]
    }
   ],
   "source": [
    "print(dir(benchpots.datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 14:36:06 [INFO]: You're using dataset italy_air_quality, please cite it properly in your work. You can find its reference information at the below link: \n",
      "https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/italy_air_quality\n",
      "2024-11-08 14:36:06 [INFO]: Dataset italy_air_quality has already been downloaded. Processing directly...\n",
      "2024-11-08 14:36:06 [INFO]: Dataset italy_air_quality has already been cached. Loading from cache directly...\n",
      "2024-11-08 14:36:06 [INFO]: Loaded successfully!\n",
      "2024-11-08 14:36:06 [INFO]: Total sample number: 777\n",
      "2024-11-08 14:36:06 [INFO]: Training set size: 467 (60.10%)\n",
      "2024-11-08 14:36:06 [INFO]: Validation set size: 155 (19.95%)\n",
      "2024-11-08 14:36:06 [INFO]: Test set size: 155 (19.95%)\n",
      "2024-11-08 14:36:06 [INFO]: Number of steps: 12\n",
      "2024-11-08 14:36:06 [INFO]: Number of features: 13\n",
      "2024-11-08 14:36:06 [INFO]: Train set missing rate: 10.03%\n",
      "2024-11-08 14:36:06 [INFO]: Validating set missing rate: 10.04%\n",
      "2024-11-08 14:36:06 [INFO]: Test set missing rate: 10.07%\n"
     ]
    }
   ],
   "source": [
    "italy_air_quality_data = preprocess_italy_air_quality(\n",
    "    subset=\"all\", rate=0.1, n_steps=12  # Replace 12 with your desired sequence length\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['n_steps', 'n_features', 'scaler', 'train_X', 'val_X', 'test_X', 'train_X_ori', 'val_X_ori', 'test_X_ori'])\n"
     ]
    }
   ],
   "source": [
    "print(italy_air_quality_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# assemble the datasets for training\n",
    "dataset_for_training = {\n",
    "    \"X\": italy_air_quality_data['train_X'],\n",
    "}\n",
    "# assemble the datasets for validation\n",
    "dataset_for_validating = {\n",
    "    \"X\": italy_air_quality_data['val_X'],\n",
    "    \"X_ori\": italy_air_quality_data['val_X_ori'],\n",
    "}\n",
    "# assemble the datasets for test\n",
    "dataset_for_testing = {\n",
    "    \"X\": italy_air_quality_data['test_X'],\n",
    "}\n",
    "## calculate the mask to indicate the ground truth positions in test_X_ori, will be used by metric funcs to evaluate models\n",
    "# Use italy_air_quality_data instead of preprocess_italy_air_quality\n",
    "test_X_indicating_mask = np.isnan(italy_air_quality_data['test_X_ori']) ^ np.isnan(italy_air_quality_data['test_X'])  \n",
    "test_X_ori = np.nan_to_num(italy_air_quality_data['test_X_ori'])  # metric functions do not accpet input with NaNs, hence fill NaNs with 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
